\begin{table}[H]
\begin{center}
\footnotesize
\begin{tabular}{|l|c|c|c|c|r|}
\hline
\multicolumn{6}{|c|}{Confusion matrix} \\
\hline
 Classes & 1 (1) & 2 (4) & 3 (5) & 4 (13) & Precision \\
\hline
1 (1) & 2118007 & 1016 & 57835 & 45150 & 95.32 \\
\hline
2 (4) & 1913 & 25818 & 0 & 2224 & 86.19 \\
\hline
3 (5) & 517 & 0 & 152774 & 8420 & 94.47 \\
\hline
4 (13) & 63771 & 1016 & 4869 & 1022694 & 93.62 \\
\hline
Recall & 96.97 & 92.7 & 70.9 & 94.83 &  \\
\hline
\multicolumn{6}{c}{ } \\
\hline
\multicolumn{6}{|c|}{Accuracy metrics} \\
\hline
 Classes & 1 (1) & 2 (4) & 3 (5) & 4 (13) & Overall \\
\hline
IU & 92.56 & 80.71 & 68.08 & 89.07 & 82.61 \\
\hline
F-score & 96.14 & 89.33 & 81.01 & 94.22 & 90.17 \\
\hline
Accuracy & 95.15 & 99.82 & 97.96 & 96.42 & 94.67 \\
\hline
P0 & 0.95 & 1 & 0.98 & 0.96 & 0.95 \\
\hline
Pe & 0.53 & 0.98 & 0.9 & 0.57 & 0.49 \\
\hline
$\kappa$ & 0.8961 & 0.8924 & 0.7995 & 0.9163 & 0.8948 \\
\hline
\end{tabular}
\caption{Confusion Matrix and accuracy metrics of the regularization when not selecting training samples.}
\label{table:C3_S3_ss3_regul_without_training}
\end{center}
\end{table}