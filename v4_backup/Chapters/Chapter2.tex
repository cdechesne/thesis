% Chapter 2

\chapter{Method} % Main chapter title
\label{Chapter2} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\startcontents[chapters]
\Mprintcontents


%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
%\newcommand{\keyword}[1]{\textbf{#1}}
%\newcommand{\tabhead}[1]{\textbf{#1}}
%\newcommand{\code}[1]{\texttt{#1}}
%\newcommand{\file}[1]{\texttt{\bfseries#1}}
%\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------

\section{General flowchart}

With respect to the methods mentioned above, it appears that there are no forest stand segmentation method, based on tree species, that can satisfactorily handle a large number of classes ($>$5). The proposed framework is a fully automatic and modular method for species-based forest stand segmentation. The method is composed of four main steps. An over-segmentation is firstly performed in order to retrieve relevant objects. Features are then computed at the pixel level for the optical images and at the point level for the lidar data. The object extracted from the over-segmentation and the computed features allows to derive features at the object level. A classification of the vegetation type (mainly tree species) is then performed at the object level, since it significantly improve the discrimination results. Here, the training set is automatically derived from an existing forest LC database. Specific attention is paid to the extraction of the most relevant training pixels, which is highly challenging with outdated and generalized vector databases. Because of the high number of features, a feature selection is also carried out in order to increase the classification accuracy, reduce the computational load and time, but also to assess the complementarity of the features (multispectral optical images/lidar point cloud). Finally, a regularization is performed in order to retrieve homogeneous forest stands. The flowchart of the method is presented in Figure \ref{fig:flowchart}.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{Figures/method.eps}
\caption{Flowchart of the proposed method.}
\label{fig:flowchart}
\end{center}
\end{figure}

\section{Over-segmentation}
The over-segmentation aims to extract small object that are consistent according to the input data. They are detected so as to ease and strengthen subsequent classification task. A precise extraction is not mandatory since the labels would be refined after.

\subsection{Segmentation of lidar data}
Two approaches could be envisaged: the direct segmentation of the point cloud or the segmentation of a rasterized lidar feature using image-based segmentation algorithms. \\

The tree extraction from the point cloud is a complex task that has been widely discussed \citep{dalponte2014tree, vega2014ptrees, kandare2014new}. However, a precise tree extraction is not needed here, since the extracted trees are only needed to improve the classification task. A coarse method is therefore adopted: the tree tops are first extracted from the lidar point clouds using a local maximum filter. A point is considered as a tree top when it has the highest height value within a 5 meter radius. Only the points above 3$\:$meters are retained as it is a common threshold of the literature \citep{eysn2012forest}, and appears to be highly discriminative in non-urban areas. Points belonging to a tree are obtained through two criteria. (i) If the height of a point within a 5$\:$m radius is greater or equal than 80\% the height of the closest tree top, it is aggregated to the tree top. (ii) If the distance in the  $(x,y)$ plane between an unlabeled point and the closest tree point is smaller than 3$\:$m  they are also aggregated. This delineation method allows to discard low vegetation, but buildings might be extracted and considered as trees. \\

The image-based segmentation are also very efficient for the over-segmentation of lidar data. They are mainly applied on the normalized digital surface model (height). Thus a method using a single band is needed. The watershed algorithm \citep{vincent1991watersheds} with specific parameters allow to obtain quickly a consistent over-segmentation of the image. A hierarchical segmentation \citep{guigues2006scale} is more adapted since only one parameter that control the segmentation level needs to be provided.

\subsection{Segmentation of images}
Several algorithms have been developed for the over-segmentation of optical RGB (Red-Green-Blue) images. The most common are the superpixels methods \citep{achanta2012slic}. Superpixels can be generated using segmentation algorithms \citep{shi2000normalized, felzenszwalb2004efficient, comaniciu2002mean, vedaldi2008quick, vincent1991watersheds}. A special attention must be paid to the parameters in order to obtain relevant superpixels. These methods produces superpixels that might not be homogeneous in terms of size and shape but delineate precisely objects.
Superpixels algorithms have then been developed, they allow to control the number of superpixel, their size and their shape \citep{moore2008superpixel, veksler2010superpixels, levinshtein2009turbopixels, achanta2012slic}.
For the over-segmentation of the optical images, we will use both "traditional" and superpixels methods.

Five methods have been employed for the segmentation of images (VHR optical images or rasterized lidar features):
\begin{itemize}
\item The watershed algorithm \citep{vincent1991watersheds},
\item A segmentation algorithm based on graph-cut (called here PFF) \citep{felzenszwalb2004efficient},
\item A multilevel hierarchical segmentation algorithms \citep{guigues2006scale},
\item A segmentation algorithm based on the mean shift algorithm (called quickshift) \citep{vedaldi2008quick},
\item A superpixel algorithm (called SLIC) \citep{achanta2012slic}.
\end{itemize}

\paragraph{Watershed. \\}
Watershed segmentation "classifies" pixels into regions using gradient descent on image features and analysis of weak points along region boundaries. It has been proposed after the observation natural observation of water raining onto a landscape topology and flowing with gravity to collect in low basins. The size of those basins will grow with increasing amounts of precipitation until they spill into one another, causing small basins to merge together into larger basins. Regions (catchment basins) are formed by using local geometric structure to associate points in the image domain with local extrema in some feature measurement such as curvature or gradient magnitude. This technique is less sensitive to user-defined thresholds than classic region-growing methods, and may be better suited for fusing different types of features from different data sets. The watersheds technique is also more flexible in that it does not produce a single image segmentation, but rather a hierarchy of segmentations from which a single region or set of regions can be extracted a-priori.

\paragraph{PFF. \\}
This algorithm define a predicate for measuring the evidence for a boundary between two regions using a graph-based representation of the image. An efficient segmentation algorithm based on this predicate is employed, and show that although this algorithm makes greedy decisions it produces a segmentation that satisfy global properties. The algorithm runs in time nearly linear in the number of graph edges and is also fast in practice. An important characteristic of the method is its ability to preserve detail in low-variability image regions while ignoring detail in high-variability regions.

\paragraph{Hierarchical segmentation. \\}
This segmentation method introduces a multi-scale theory of piecewise image modeling, called the scale-sets theory, and which can be regarded as a region-oriented scale-space theory. A general formulation of the partitioning problem which involves minimizing a two-term-based energy, of the form $D + \mu C$, where $D$ is a goodness-of-fit term and $C$ is a regularization term. Such energies arise from basic principles of approximate modeling and relate them to operational rate/distortion problems involved in lossy compression problems. An important subset of these energies constitutes a class of multi-scale energies in that the minimal cut of a hierarchy gets coarser and coarser as parameter $\mu$ increases. This allows to devise a procedure to find the complete scale-sets representation of this family of minimal cuts. Considering then the construction of the hierarchy from which the minimal cuts are extracted, ending up with an exact and parameter-free algorithm to build scale-sets image descriptions whose sections constitute a monotone sequence of upward global minima of a multi-scale energy, which is called the "scale climbing" algorithm. This algorithm can be viewed as a continuation method along the scale dimension or as a minimum pursuit along the operational rate/distortion curve. Furthermore, the solution verifies a linear scale invariance property which allows to completely postpone the tuning of the scale parameter to a subsequent stage.

\paragraph{Quickshift \\}
Quickshift \citep{vedaldi2008quick} is a kernelized version of a mode seeking algorithm similar in concept to mean shift \citep{comaniciu2002mean, fukunaga1975estimation} or medoid shift \citep{sheikh2007mode}. Given $N$ data points $x_{1} , \hdots , x_{N}$, it computes a Parzen density estimate around each point using, for example, an isotropic Gaussian window:
\begin{equation}
P(x)=\frac{1}{2 \pi \sigma^{2} N}\sum_{i=1}^{N}e^{\frac{-||x-x_{i}||^{2}}{2 \sigma^{2}}}
\end{equation}
Once the density estimate $P(x)$ has been computed, quick shift connects each point to the nearest point in the feature space which has a higher density estimate. Each connection has a distance $d_{x}$ associated with it, and the set of connections for all pixels forms a tree, where the root of the tree is the point with the highest density estimate. 
To obtain a segmentation from a tree of links formed by quick shift, a threshold $\tau$ is chosen and break all links in the tree with $d_ {x} > \tau$ . The pixels which are a member of each resulting disconnected tree form each segment.

\paragraph{SLIC superpixels. \\}
The SLIC superpixel algorithm \citep{achanta2012slic} clusters pixels in the combined five-dimensional color (CIELAB color space) and image plane (xy) space to efficiently generate compact, nearly uniform superpixels. It is basically based on the k-mean algorithm. The number of desired cluster corresponds to the number of desired superpixels. The employed distance is based on a weighted sum of a color based distance and a plane space distance. This method produces superpixels achieving a good segmentation quality measured by boundary recall and under-segmentation error. The benefits of superpixel approaches have already been shown, as they increase performance over pixel-based methods.


\section{Feature extraction}
The extraction of feature is an important step in order to obtain an accurate classification. The feature can be handcrafted. Such feature have been extensively employed for remote sensing application. The features could also be learned for a specific classification task using convolutional neural networks \citep{demuth2014neural}. Here, the proposed features have been derived manually, most are standards of the literature.
\subsection{Point-based lidar features.}
Lidar-derived features require a consistent neighborhood for their computation. For each lidar point, 3 cylindrical neighborhoods, aligned with the vertical axis, are used (1$\:$m, 3$\:$m and 5$\:$m radii, infinite height). A cylinder appears to be the most relevant environment in forested areas so as to take into account the variance of altitudes of the lidar points. Three radius values are considered so as to handle the various sizes of the trees and assuming a feature selection step will prune the initial set of attributes. Two vegetation density features, $\mathcal{D}_{1}$ and $\mathcal{D}_{2}$, are computed: the first one based on the number of local maxima within the neighborhoods, and the second one related to the number of non-ground points within the neighborhoods (ground points were previously determined by a filtering step). $\mathcal{D}_{1}$ and $\mathcal{D}_{2}$ are calculated as follows:
\begin{eqnarray}
\mathcal{D}_{1} & = & \sum_{r_{1} \in \{1,3,5\}}\sum_{r_{2} \in \{1,3,5\}}Nt_{r_{1},r_{2}}, \\
\mathcal{D}_{2} & = & \frac{1}{3}\sum_{r \in \{1,3,5\}}\frac{Ns_{r}}{Ntot_{r}},
\end{eqnarray}
where $Nt_{r_{1},r_{2}}$ is the number of local maxima retrieved from a $r_{1}$ maximum filter within the cylindrical neighborhood of radius $r_{2}$. $Ns_{r}$ is the number of points classified as ground points within the cylindrical neighborhood of radius $r$ and $Ntot_{r}$ is the total number of points within the cylindrical neighborhood of radius $r$. Additionally, the scatter $\mathcal{S}$ and the planarity $\mathcal{P}$ features are computed following \citet{Weinmann2015286}:
\begin{eqnarray}
\mathcal{S} & = & \frac{1}{3}\sum_{r \in \{1,3,5\}}\frac{\lambda_{3,r}}{\lambda_{1,r}}, \\
\mathcal{P} & = & \frac{1}{3}\sum_{r \in \{1,3,5\}}2\times(\lambda_{2,r}-\lambda_{3,r}),
\end{eqnarray}
where $\lambda_{1,r}\geq\lambda_{2,r}\geq\lambda_{3,r}$ are the eigenvalues of the covariance matrix within the cylindrical neighborhood of radius $r$. They are retrieved with a standard Principal Component Analysis. \\
Statistical features, known to be relevant for vegetation type (mainly tree species) classification \citep{dalponte2014tree,torabzadeh2015optimal}, are also derived. For each lidar point, the same 3 cylindrical neighborhoods are used. Two basic information from the lidar data, namely height and intensity, are used to derive statistical features. A statistical feature $f_{d}$, derived from an original feature $f_{o}$, (height or intensity) is computed as follows: \\
\begin{equation}
f_{d} = \frac{1}{3}\sum_{r \in \{1,3,5\}}f_{s}(\mathbf{p_{r,f_{o}}}), 
\label{eq:derive_features}
\end{equation}
where $f_{s}$ is a statistical function (minimum; maximum; mean; median; standard deviation; median absolute deviation from median (medADmed); mean absolute deviation from median (meanADmed); skewness; kurtosis; 10$^{\text{th}}$, 20$^{\text{th}}$, 30$^{\text{th}}$, 40$^{\text{th}}$, 50$^{\text{th}}$, 60$^{\text{th}}$, 70$^{\text{th}}$, 80$^{\text{th}}$, 90$^{\text{th}}$ and 95$^{\text{th}}$ percentiles), and $\mathbf{p_{r,f_{o}}}$ a vector containing the sorted values of the original feature $f_{o}$ within the cylindrical neighborhoods of radius~$r$. All the statistical functions are used for the height. Only the mean is used for the intensity: it is hard to know how well the sensor is calibrated and a suitable correction of intensity values within tree canopies has not yet been proposed. \\
24 features are extracted during this step; 2 related to vegetation density, 2 related to the 3D local distribution of the point cloud (planarity and scatter), and 20 statistical features.

\subsection{Pixel-based multispectral features.}
The original 4 spectral bands of the image are kept and considered as multispectral features. The Normalized Difference Vegetation Index (NDVI), \citep{tucker1979red},
the Difference Vegetation Index (DVI), \citep{bacour2006normalization}
and the Ratio Vegetation Index (RVI) \citep{jordan1969derivation}
are computed as they are relevant vegetation indices. Many other vegetation indices have been proposed \citep{bannari1995review}. Indeed, they can provide more information about the species than the original bands alone \citep{zargar2011review}. As the point-based lidar features, statistical features are also derived from each band and each vegetation index according to Equation~\ref{eq:derive_features} (3 circular neighborhoods of 1$\:$m, 3$\:$m and 5$\:$m radii). Other statistical functions are used (minimum; maximum; mean; median; standard deviation; mean absolute deviation from median (meanADmed); mean absolute deviation from mean (meanADmean); median absolute deviation from median (medADmed); median absolute deviation from mean (medADmean). Finally, the pixel-based multispectral feature set is composed of 70 attributes.

\subsection{Pixel-based lidar features.}
The lidar features are rasterized at the same resolution of the multispectral image using a pit-free method proposed in \citep{khosravipour2014generating}. This rasterization method is interesting because it produces smooth images that will lead to better results for classification and regularization \citep{Li2013104}. Such data fusion process at the feature level is valid since both datasets have approximately the same spatial resolution. The Canopy Height Model (CHM) is also computed using this method, at the same spatial resolution using an existing 1$\:$m Digital Terrain Model provided with the filtered point cloud \citep{Ferraz201623}. The CHM is very important as it allows to derive the height above the ground and is known as a very discriminative feature for classification \citep{Mallet2011S71,Martin}.

\subsection{Object-based feature map.}
The pixel-based multispectral and lidar maps are merged so as to obtain a pixel-based feature map. Then, an object-based feature map is created using the over-segmentation and the pixel-based feature map. The value $v_{t}$ of a pixel belonging to an object $t$ in the object-based feature map is computed as follows:
\begin{equation}
v_{t}=\frac{1}{N_{t}}\sum_{p \in t} v_{p},
\end{equation}
where $N_{t}$ is the number of pixels in object $t$ ,and $v_{p}$ is the value of the pixel $p$.
If a pixel does not belong to a tree, it keeps the value of the pixel-based feature map. Here, only the mean value of the pixels within the tree is envisaged but one can also consider other statistical values (minimum, maximum, percentiles etc.). \\
Other morphological features could also be directly derived from the lidar cloud point at the object-level. For instance, an alpha-shape can be performed on the individual trees \citep{vauhkonen2010imputation} and a penetration feature can be derived as it can help to classify vegetation type (mainly tree species). However, low point densities (1-5 points/m$^{2}$) compatible with large-scale lidar surveys are not sufficient in order to derive a significant penetration indicator.

\section{Classification}
The classification is performed using a supervised classifier, in order to discriminate the vegetation type (mainly tree species) provided by an existing forest land-cover database. The classifier used in this study is the Random Forest (RF), implemented in OpenCV \citep{opencv}, as it has been shown relevant in the literature \citep{belgiu2016random} and in a previous study compared to SVM \citep{dechesne2016forest}, since it provide similar results while being faster. Indeed, the SVM classifier very efficient \citep{vapnik2013nature}, however, the training of such classifier is time consuming, especially when the number of training sample increases (which is the case when the learning is based on a database). Furthermore, when using different type of feature (here spectral and lidar features) a special attention should pe paid to the employed kernel. The RF classifier is therefore preferred because is natively handle features of different type and works better when the number of samples increases. The outputs of the classification are (i) label map and (ii) probability map (posterior class probabilities for each pixel/object). This probability map is the main input for the subsequent regularization step. \\
In order to reduce the computation times, a feature selection is carried out to identify an "optimal" feature subset. Additionally, a strategy is proposed in order to select the most suitable training pixels for an existing land-cover forest maps, subsequently improving the classification accuracy.

\subsection{Training set design}
Using an existing forest land-cover (LC) database for training a model is not straightforward \citep{isprsannals-II-3-W2-13-2013,rs6053965,isprs-annals-III-7-133-2016}. First, locally it can suffer from a lack of information (not all the classes of interest are present). Secondly, this database may also be semantically and, more frequently, geometrically incorrect: changes may have happened (forest cut or grow) and the geodatabase may have been generalized, resulting in sharp polygon vertices that do not exactly correspond to the class borders. Thirdly, in many forest LC databases, polygons of a given vegetation type (mainly tree species) may contain other vegetation type (mainly tree species) in a small proportion.

%Firstly, in order to increase the knowledge on existing class labels, the model could be trained on a larger area. The size of the training area has been chosen arbitrarily. However, when it is too large, we observe that the quality of the classification decreases. The optimal choice of the training area has not been investigated yet. The model has therefore been trained on a larger area than the ones of interest. The areas selected for the training are the ones maximizing the number of classes within a 5$\:$km search zone.

In order to correct the potential errors of the LC database, a k-means clustering has been therefore performed on each of the labels in the training area. We assume that erroneous pixels are present in a small proportion and that therefore the main cluster corresponds to the class of interest. Let $p_{i-c,t}$ be the $i^{\text{th}}$ pixel of the vegetation type (mainly tree species) $t$ in the cluster $c$ of the k-means. The pixels $P_{t}$ used to train the model for the vegetation type (mainly tree species) $t$ correspond to the set:
\begin{equation}
P_{t} = \{{p_{i-c,t} \quad | \quad \underset{c \in [1,k]}{c=\text{argmax }}\text{Card} ( \cup_{i} p_{i-c,t} ) } \}.
\end{equation}
That is to say, only samples belonging to the main k-mean cluster among training pixels for one class are kept in the training dataset. \\
In practice, $k=3$: the main cluster corresponds to the label of interest whereas the two other ones correspond to the ground and minority vegetation type (mainly tree species) within the polygons. 1000 samples per class are then randomly selected in order to design the final training set. Such selection is a bit exclusive and does not allow a lot of variability of the selected training pixels. A more reasonable way to select training pixels is to keep the pixels such as:
\begin{equation}
P_{t} = \{p_{i-c,t} \quad | \quad  \frac{\text{Card}\left(\underset{\forall i}{\cup} p_{i-c,t}\right)}{\text{Card}\left(\underset{\forall i, \forall c_{k}}{\cup} p_{i-c_{k},t}\right)} \geq u_{p}\}.
\end{equation}
where $u_{p}$ is a proportion defined by the user.
Such selection is equivalent to select the pixels that are in a cluster which size represent a significant proportion of the total pixels labeled as $t$ in the Forest LC. in this case, the number of clusters for the k-mean can be increased. In the experiments, $u_{p}$ was set to $0.3$ (i.e. 30\%) an $k$ to $4$.

\subsection{Feature selection}
Due to the high number of features involved, an automatic Feature Selection (FS) has been integrated. This selection is composed of two steps: the choice of the number of features to select and the feature selection itself. Indeed, the choice of the number of features is very important because it enables to greatly decrease the computation times. \\
The Sequential Forward Floating Search (SFFS) \citep{pudil1994floating} algorithm is used for both steps. The SFFS algorithm has two main advantages: (i) it can be used with many classification score (in this study, the Kappa coefficient), (ii) it enables to access to the evolution of the classification score/accuracy according to the number of selected features. The accuracy of the classification is assessed through the Kappa coefficient of the RF classifier. The SFFS algorithm selects $p$ features by maximizing FS score criterion (the Kappa coefficient). In order to retrieve the optimal number of features, the SFFS algorithm is performed $n$ times on different training sets with $p$ equal to the total number of features (95). The classification accuracy is conserved for each selection of $s$ features ($s \in [1, p]$) and averaged over the $n$ iterations. The number of optimal features $n_{\text{opt}}$ corresponds to the size of the selection of $s$ features having the maximal mean accuracy. \\
The feature selection is then carried out for each area of interest (one selection for each area) with $p=n_{\text{opt}}$. The selected features are used for both the classification and the energy minimization framework. The feature selection could be carried out only once samples from multiple areas in order to retrieve the relevant features and thus only compute them.

\section{Smoothing}
After the classification, we assume that a label map is provided for the areas of interest, and is accompanied with a class membership probability map, which provides, for each pixel of the image, the posterior class membership for all classes of interest. These are the necessary inputs for all methods described below. \\
Here, both local and global methods are tested. For local techniques, majority voting and probabilistic relaxation are selected. For global methods, various energy formulations based on a feature-sensitive Potts model are proposed.

\subsection{Local methods}
\subsubsection{Filtering}
An easy way to smooth a probability map is to filter it. All the pixels in a $r \times r$ pixels moving window $\mathcal{W}$ are combined in order to generate an output label of the central pixel. The most popular filter is the majority filter. Firstly, the class probabilities are converted into labels, assuming that the label of pixel $\mathbf{x}$ is the label of the most probable class.\\
\begin{equation}
C(\mathbf{x})=[c_{i}|P(\mathbf{x},c_{i}) \geq P(\mathbf{x},c_{j}) \forall j],
\end{equation}
with $i,j \in [1,n_{c}]$, where $n_{c}$ is the number of classes. From this label image, the final smoothed result is obtained by taking the majority vote in a local neighborhood.
\begin{equation}
C_{smooth}(\mathbf{x})=\underset{i}{\text{arg max}}\left[ \sum_{\mathbf{u}\in\mathcal{W}}\left[C(\mathbf{u})=c_{i}\right] \right].
\end{equation}
The majority filter does not take into account the original class posterior likelihoods. For example, if in a $5 \times 5$ neighborhood, 13 pixels have a probability of $51\%$ for class \textit{Douglas fir}, and the 12 other pixels have a $99\%$ probability for class \textit{beech}, the voting will nevertheless prefer \textit{Douglas fir}. There are variants which give pixels closer to the center more voting power, but typically yield similar results.
Other filters have been developed such as the Gaussian Filter, the Bilateral Filter \citep{paris2006fast, paris2009bilateral} and the Edge-Aware Filter \citep{chen2007real}.

\subsubsection{Probabilistic relaxation}
The probabilistic relaxation aims at homogenizing probabilities of a pixel according to its neighboring pixels. The relaxation is an iterative algorithm in which the probability at each pixel is updated at each iteration in order to have it closer to the probabilities of its neighbors \citep{Gong198933}. It was adopted for simplicity reasons. First, good accuracies are reported with decent computing time, which is beneficial over large scales. Secondly, it offers an alternative to edge aware/gradient-based techniques that may not be adapted in semantically unstructured environments like forests. The probability $P_{k}^{t}(\mathbf{u})$ of class $k$ at a pixel $\mathbf{u}$ at the iteration $t$ is defined by  $\delta P_{k}^{t}(\mathbf{u})$ which depends on:
\begin{itemize}
\item The distance $d_{\mathbf{u},\mathbf{v}}$ between the pixel $\mathbf{u}$ and its neighbors $\mathbf{v}$ (the pixels that are distant of less than $r$ pixels from $\mathbf{u}$).
\item A co-occurrence matrix $T_{k,l}$ defining a priori correlation between the probabilities of neighboring pixels. The local co-occurrence matrix has been tuned arbitrarily, but can also be estimated using training pixels \citep{VolpiCVPR2015}. The matrix is expressed as follow: \\
$T_{k,l}=\begin{bmatrix}
0.8 & p & \cdots & p \\
p & \ddots & \ddots & \vdots \\
\vdots & \ddots & \ddots & p \\
p & \cdots & p & 0.8
\end{bmatrix}$, with $p=\frac{0.2}{n_{c}-1}$.
\end{itemize}
The update factor is then defined as:
\begin{equation}
\delta P_{k}^{t}(\mathbf{u})=\sum_{\mathbf{v} \in \mathcal{N_{\mathbf{u}}}} d_{\mathbf{u},\mathbf{v}} \sum_{l=1}^{n_{c}} T_{k,l}(\mathbf{u},\mathbf{v}) \times P_{l}^{t}(\mathbf{v}).
\end{equation}
In order to keep the probabilities normalized, the update is performed in two steps using the unnormalized probability $Q_{k}^{t+1}(\mathbf{u})$ of class $k$ at a pixel $\mathbf{u}$ at the iteration $t+1$:
\begin{equation}
Q_{k}^{t+1}(\mathbf{u})=P_{k}^{t}(\mathbf{u}) \times \big(1 + \delta P_{k}^{t}(\mathbf{u})\big),
\end{equation}
\begin{equation}
P_{k}^{t+1}(\mathbf{u})=\frac{Q_{k}^{t+1}(\mathbf{u})}{\sum_{l=1}^{n_{c}}Q_{l}^{t+1}(\mathbf{u})}.
\end{equation}

\subsection{Global smoothing}
The global smoothing method uses only a small number of pairwise cliques between neighboring pixuseels (4-neighbors or 8-neighbors) to describe the smoothness. Over the entire resulting first order random fields, the maximization of the posterior probability leads to a smoothed results. This can be done by finding the minimum of the negative log-likelihood, $\underset{C}{\text{arg min}}E(I,C,A)$ with
\begin{equation}
\begin{aligned}
& E(I,C,A)=\sum_{\mathbf{u}\in I}E_{\text{data}}(\mathbf{u},P(\mathbf{u})) + \\
& \gamma\sum_{\mathbf{u} \in I, \mathbf{v} \in \mathcal{N}_{\mathbf{u}}} E_{\text{pairwise}}(\mathbf{u}, \mathbf{v}, C(\mathbf{u}), C(\mathbf{v}), A(\mathbf{u}), A(\mathbf{v})),
\end{aligned}
\end{equation}
where $P(\mathbf{u})=[P(\mathbf{u},c_{i})|P(\mathbf{u},c_{i}) \geq P(\mathbf{u},c_{j}) \forall j]$, $A(\mathbf{u})$ are the values of the features at pixel $\mathbf{u}$ (such as height, reflectance...) and $\mathcal{N}_{\mathbf{u}}$ is the 8-connected neighborhood of the pixel $\mathbf{u}$ (only the 8-connected neighborhood has been investigated). When $\gamma=0$, the pairwise term has no effect in the energy formulation; the most probable class is attributed to the pixel, leading to the same result as the classification output. When $\gamma \neq 0$, the resulting label map becomes more homogeneous, and the borders of the segments/stands are smoother. However, if $\gamma$ is too high, the small areas are bound to be merged into larger areas, removing a part of the useful information provided by the classification step. The automatic tuning of the parameter $\gamma$ has been addressed in \cite{Gab_MRF} but is not used here.\\

In spite of having only connections between neighbors, the optimization propagates information over larger distances. The problem is NP-hard, but strong approximate optimization algorithms exist \citep{boykov2001fast, kolmogorov2006convergent, felzenszwalb2006efficient}. \\

Here, two formulations of $E_{\text{data}}$ (unary term) and four formulations of $E_{\text{pariwise}}$ (prior) are investigated. \\
\subsubsection{Unary term}
A widely used formulation for the unary term is the log-inverse formulation using the natural logarithm. It corresponds to the information content in information theory and is formulated as follow:
\begin{equation}
E_{\text{data}}=-\text{log}(P(\mathbf{u})).
\label{eq:data1}
\end{equation}
It highly penalizes the low-probability classes but increase the complexity with potential infinite values.\\
An other simple formulation for the unary term is the linear formulation,
\begin{equation}
E_{\text{data}}=1-P(\mathbf{u}).
\label{eq:data2}
\end{equation}
It penalizes less than the log-inverse formulation but has the advantage of having values lying in $[0,1]$. \\
\subsubsection{Prior}
In this work, the prior has a value depending on the class of neighboring pixels. In the four formulations, two neighboring pixels pay no penalty if they are assigned to the same class. Two basic and popular priors, the \textit{Potts model} and the \textit{contrast-sensitive Potts model} (called here \textit{z-Potts model}), are investigated. In the \textit{Potts model}, two neighboring pixels pay the same penalty if they are assigned to different labels, the prior for the \textit{Potts model} is:
\begin{equation}
\begin{aligned}
& E_{\text{pairwise}}(C(\mathbf{u}) = C(\mathbf{v}))=0, \\
& E_{\text{pairwise}}(C(\mathbf{u}) \neq C(\mathbf{v}))=1.
\end{aligned}
\label{eq:prior1}
\end{equation}\\
In the \textit{z-Potts model}, the penalty for a change of label depends on the gradient of height between two neighboring pixels. The \textit{z-Potts model} is a standard \textit{contrast-sensitive Potts model} applied to the height obtained from the point clouds. Here, since we are dealing with forest stands that are likely to exhibit distinct heights, the gradient of the height map (given with the 3D lidar point cloud) is computed for each of the four directions separately. The maximum $M_{g}$ over the whole image in the four directions is used to compute the final pairwise energy. A linear function has been used: the penalty is highest when the gradient is 0, and decreases until the gradient reaches its maximum value. The prior of the \textit{z-Potts model} is therefore:
\begin{equation}
\begin{aligned}
& E_{\text{pairwise}}(C(\mathbf{u}) = C(\mathbf{v}))=0, \\
& E_{\text{pairwise}}(C(\mathbf{u}) \neq C(\mathbf{v}))=1-\frac{g_{\mathbf{u} \rightarrow \mathbf{v}}}{M_{g}},
\end{aligned}
\label{eq:prior2}
\end{equation}
where $g_{\mathbf{u} \rightarrow \mathbf{v}}$ is the gradient between pixel $\mathbf{u}$ and pixel $\mathbf{v}$, i.e., the absolute value of the height difference of the two pixels.\\
An other pairwise energy investigated is a global feature sensitive energy (called here \textit{Exponential-features model}). The pairwise energy is computed with respect to a pool of $n$ features. When the features have close values, the penalty is high and decreases when the features tends to be very different. The pairwise energy in this case is expressed as follows:
\begin{equation}
\begin{aligned}
& E_{\text{pairwise}}(C(\mathbf{u}) = C(\mathbf{v}))=0, \\
& E_{\text{pairwise}}(C(\mathbf{u}) \neq C(\mathbf{v}))=\frac{1}{n}\sum_{i=1}^{n}\exp({-|A_{i}(\mathbf{u})-A_{i}(\mathbf{v})|}),
\end{aligned}
\label{eq:prior3}
\end{equation}
where $A_{i}(\mathbf{u})$ is the value of the $i^{\text{th}}$ feature of the pixel $\mathbf{u}$. To compute such energy, the features need to be first normalized (i.e., zero mean, unit standard deviation) in order ensure that they all have the same dynamic.\\
The last formulation investigated is also a global feature sensitive energy (called here \textit{Distance-features model}). The pairwise energy is still computed with respect to a pool of $n$ features. In this case, the energy is computed according to the distance between the two neighboring pixels in the feature space, the penalty is high when the pixels are close in the feature space and decrease when they get distant. The pairwise energy in this case is expressed as follow:
\begin{equation}
\begin{aligned}
& E_{\text{pairwise}}(C(\mathbf{u}) = C(\mathbf{v}))=0, \\
& E_{\text{pairwise}}(C(\mathbf{u}) \neq C(\mathbf{v}))=1-||A(\mathbf{u});A(\mathbf{v})||_{n,2},
\end{aligned}
\label{eq:prior4}
\end{equation}
with
\begin{equation}
||A(\mathbf{u});A(\mathbf{v})||_{n,2}=\frac{1}{\sqrt{n}}\sqrt{\sum_{i=1}^{n}\big(A_{i}(\mathbf{u})-A_{i}(\mathbf{v})\big)^{2}}.
\end{equation}
To compute such energy, the features need to be first normalized (i.e., zero mean, unit standard deviation) in order ensure that they all have the same dynamic. They are then rescaled between $0$ and $1$ to ensure that $||A(\mathbf{u});A(\mathbf{v})||_{n,2}$ lies in $[0;1]$ $\forall (\mathbf{u},\mathbf{v})$.

In \cite{clement_IJPRS}, a high number of features was extracted from available lidar and optical images ($\sim$ 100) but can be selected. They can also be weighted according to their importance, computed through the Random Forest classification process. Since the most important features (20) are almost all equally weighted, it does not bring additional discriminative information for the global feature sensitive energy.

\subsubsection{Energy minimization}
The energy minimization is performed using graph-cut methods. The graph-cut algorithm employed is the quadratic pseudo-boolean optimization (QPBO). The QPBO is a popular and efficient graph-cut method as it efficiently solves energy minimization problems (such as the proposed ones) by constructing a graph and computing the min-cut \citep{kolmogorov2007minimizing}. $\alpha$-expansion moves are used, as they are an efficient way to deal with the multi-class problems \citep{kolmogorov2004energy}. The QPBO is an interesting method since it allows to solve any Markov Random Field optimization problems. Thus the energy formulation can be modified in order to add more constraint to the problem. Such investigation have been envisaged. Two constraints have been tested. \\

\paragraph{Size constraint. \\}
Firstly, the size of a segment can be taken into account in the energy formulation. This is done by setting the pairwise term to an important value $v_{s}$ (ideally $v_{s}=\infty$) when a pixel belong to a segment defined as too small by the user (in forested area, a minimum stand size is 0.5$\:$ha). Thus the Equation~\ref{eq:prior1} becomes:
\begin{equation}
\begin{aligned}
& E_{\text{pairwise}}(C(\mathbf{u}) = C(\mathbf{v}))=f(\mathbf{u},\mathbf{v}), \\
& E_{\text{pairwise}}(C(\mathbf{u}) \neq C(\mathbf{v}))=1 + f(\mathbf{u},\mathbf{v}),
\end{aligned}
\label{eq:prior1b}
\end{equation}\\
with
\begin{equation}
\begin{aligned}
& f(\mathbf{u},\mathbf{v})=0 \text{ if $\mathbf{u}$ and $\mathbf{v}$ are not in a small segment}, \\
& f(\mathbf{u},\mathbf{v})=v_{s} \text{ if $\mathbf{u}$ or $\mathbf{v}$ are in a small segment}.
\end{aligned}
\label{eq:prior1bf}
\end{equation}
Such constraint can be applied to the other proposed priors.

\paragraph{Border constraint. \\}
The second constraint that can easily added is a related to the borders. Indeed, it is possible the set the energy to a specific value in order  to ensure that a border will be created. However, an a priori border need to be defined. Let $b(\mathbf{u},\mathbf{v})$ be a binary function that define if a border between a pixel $\mathbf{u}$ an $\mathbf{v}$ wants to be set. If $b(\mathbf{u},\mathbf{v})=0$, no borders want to be set, thus Equation~\ref{eq:prior1} remains the same. Otherwise, if $b(\mathbf{u},\mathbf{v})=1$, Equation~\ref{eq:prior1} becomes:
\begin{equation}
\begin{aligned}
& E_{\text{pairwise}}(C(\mathbf{u}) = C(\mathbf{v}))=v_{b}, \\
& E_{\text{pairwise}}(C(\mathbf{u}) \neq C(\mathbf{v}))=0,
\end{aligned}
\label{eq:prior1c}
\end{equation}\\
with $v_{b}$ an important value (ideally $v_{b}=\infty$).

Adding constraints increases the computational load and time but might be interesting in order to refine even more the results. However, adding such constraints also leads to some issues. Firstly, even if the minimum size of a forest stand is clearly defined in the specifications of the forest LC database, forcing segment to have a minimum size could suppress some information (such as pure islets). Such generalization could be obtained by increasing the $\gamma$ parameter. Secondly, adding borders means that predetermined relevant borders could be retrieved, however, in practice, such borders can not be straightforward  extracted. Thus, adding these constraint have been considered in a limited way.


\stopcontents[chapters]